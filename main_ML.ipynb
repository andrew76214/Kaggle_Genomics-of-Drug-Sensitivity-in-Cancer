{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/andrew-root/.cache/kagglehub/datasets/samiraalipour/genomics-of-drug-sensitivity-in-cancer-gdsc/versions/2\n",
      "Loading Done!\n",
      "Preprocess Done!\n",
      "Define Done!\n"
     ]
    }
   ],
   "source": [
    "import gc, csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from DataLoader import DataLoader\n",
    "from model.MLP import MLP_Tuner\n",
    "from ML_model import DecisionTree_Tuner, CatBoost_Tuner, ElasticNet_Tuner, HistGradientBoosting_Tuner, KNN_Tuner, \\\n",
    "    Lasso_Tuner, LGBM_Tuner, LinearRegression_Tuner, RF_Tuner, Ridge_Tuner, SVR_Tuner, XGBRegressor_Tuner\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"samiraalipour/genomics-of-drug-sensitivity-in-cancer-gdsc\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataloader = DataLoader(path + '/GDSC_DATASET.csv',\n",
    "                        path + '/Compounds-annotation.csv',\n",
    "                        path + '/GDSC2-dataset.csv',\n",
    "                        path + '/Cell_Lines_Details.xlsx')\n",
    "\n",
    "X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, input_dim = dataloader.get_data()\n",
    "\n",
    "'''queue = [MLP_Tuner, DecisionTree_Tuner, CatBoost_Tuner, ElasticNet_Tuner, HistGradientBoosting_Tuner, KNN_Tuner, \\\n",
    "    Lasso_Tuner, LGBM_Tuner, LinearRegression_Tuner, RF_Tuner, Ridge_Tuner, SVR_Tuner, XGBRegressor_Tuner]'''\n",
    "    \n",
    "queue = [XGBRegressor_Tuner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ <class 'ML_model.XGBRegressor_Tuner'> ************************\n",
      "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 300, 'subsample': 0.6}\n",
      "Best Score: -0.04561541477839152\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'max_epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mtune_hyperparameters(X_train_tensor, y_train_tensor)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Evaluate the best model on the test set\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# train_losses = []\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# val_losses = []\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_epochs\u001b[49m):\n\u001b[1;32m     16\u001b[0m     best_model\u001b[38;5;241m.\u001b[39mpartial_fit(X_train_tensor, y_train_tensor)\n\u001b[1;32m     17\u001b[0m     train_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_train_tensor)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'max_epochs'"
     ]
    }
   ],
   "source": [
    "experimental_result = []\n",
    "\n",
    "for i in range(len(queue)):\n",
    "    # Initialize the tuner\n",
    "    print(\"************************ \" + str(queue[i]) + \" ************************\")\n",
    "    tuner = queue[i](input_dim)\n",
    "\n",
    "    # Tune hyperparameters\n",
    "    best_model = tuner.tune_hyperparameters(X_train_tensor, y_train_tensor)\n",
    "    \n",
    "    # Evaluate the best model on the test set\n",
    "    # train_losses = []\n",
    "    # val_losses = []\n",
    "\n",
    "    for epoch in range(best_model.max_epochs):\n",
    "        best_model.partial_fit(X_train_tensor, y_train_tensor)\n",
    "        train_pred = best_model.predict(X_train_tensor).squeeze()\n",
    "        val_pred = best_model.predict(X_test_tensor).squeeze()\n",
    "        '''train_loss = mean_squared_error(y_train_tensor.numpy(), train_pred)\n",
    "        val_loss = mean_squared_error(y_test_tensor.numpy(), val_pred)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)'''\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        predictions = best_model.predict(X_test_tensor).squeeze()\n",
    "        predictions = torch.tensor(predictions)    \n",
    "    \n",
    "        # Calculate RMSE, MAE, and MSE\n",
    "        rmse = torch.sqrt(nn.MSELoss()(predictions, y_test_tensor)).item()\n",
    "        mae = mean_absolute_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "        mse = mean_squared_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "        \n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        print(f\"Test MSE: {mse:.4f}\")\n",
    "        \n",
    "        experimental_result.append({\"model\": str(queue[i]), \"rmse\": rmse, \"mae\": mae, \"mse\": mse})\n",
    "\n",
    "# 指定輸出檔案名稱\n",
    "csv_filename = \"model_results.csv\"\n",
    "\n",
    "# 將結果寫入 CSV 檔案\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"model\", \"rmse\", \"mae\", \"mse\"])\n",
    "    writer.writeheader()  # 寫入標題\n",
    "    writer.writerows(experimental_result)  # 寫入每行數據\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' has been created!\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tuner\n",
    "MLP_tuner = MLP_Tuner(input_dim)\n",
    "\n",
    "# Tune hyperparameters\n",
    "best_model = MLP_tuner.tune_hyperparameters(X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(best_model.max_epochs):\n",
    "    best_model.partial_fit(X_train_tensor, y_train_tensor)\n",
    "    train_pred = best_model.predict(X_train_tensor).squeeze()\n",
    "    val_pred = best_model.predict(X_test_tensor).squeeze()\n",
    "    train_loss = mean_squared_error(y_train_tensor.numpy(), train_pred)\n",
    "    val_loss = mean_squared_error(y_test_tensor.numpy(), val_pred)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Plot training and validation loss to check for overfitting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, best_model.max_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, best_model.max_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "# best_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = best_model.predict(X_test_tensor).squeeze()\n",
    "    predictions = torch.tensor(predictions)    \n",
    "    \n",
    "    # Calculate RMSE, MAE, and MSE\n",
    "    rmse = torch.sqrt(nn.MSELoss()(predictions, y_test_tensor)).item()\n",
    "    mae = mean_absolute_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "    mse = mean_squared_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "    \n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test MSE: {mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
