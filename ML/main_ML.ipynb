{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from DataLoader import DataLoader\n",
    "from ML_model import DecisionTree_Tuner, CatBoost_Tuner, ElasticNet_Tuner, HistGradientBoosting_Tuner, KNN_Tuner, \\\n",
    "    Lasso_Tuner, LGBM_Tuner, LinearRegression_Tuner, RF_Tuner, Ridge_Tuner, SVR_Tuner, XGBRegressor_Tuner\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"samiraalipour/genomics-of-drug-sensitivity-in-cancer-gdsc\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataloader = DataLoader(path + '/GDSC_DATASET.csv',\n",
    "                        path + '/Compounds-annotation.csv',\n",
    "                        path + '/GDSC2-dataset.csv',\n",
    "                        path + '/Cell_Lines_Details.xlsx')\n",
    "\n",
    "X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, input_dim = dataloader.get_data()\n",
    "\n",
    "queue = [DecisionTree_Tuner, CatBoost_Tuner, ElasticNet_Tuner, HistGradientBoosting_Tuner, KNN_Tuner, \\\n",
    "    Lasso_Tuner, LGBM_Tuner, LinearRegression_Tuner, RF_Tuner, Ridge_Tuner, SVR_Tuner, XGBRegressor_Tuner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_result = []\n",
    "\n",
    "for i in range(len(queue)):\n",
    "    # Initialize the tuner\n",
    "    print(\"************************ \" + str(queue[i]) + \" ************************\")\n",
    "    tuner = queue[i](input_dim)\n",
    "\n",
    "    # Tune hyperparameters\n",
    "    best_model = tuner.tune_hyperparameters(X_train_tensor, y_train_tensor)\n",
    "    \n",
    "    # Evaluate the best model on the test set\n",
    "    # train_losses = []\n",
    "    # val_losses = []\n",
    "\n",
    "    for epoch in range(best_model.max_epochs):\n",
    "        best_model.partial_fit(X_train_tensor, y_train_tensor)\n",
    "        train_pred = best_model.predict(X_train_tensor).squeeze()\n",
    "        val_pred = best_model.predict(X_test_tensor).squeeze()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        predictions = best_model.predict(X_test_tensor).squeeze()\n",
    "        predictions = torch.tensor(predictions)    \n",
    "    \n",
    "        # Calculate RMSE, MAE, and MSE\n",
    "        rmse = torch.sqrt(nn.MSELoss()(predictions, y_test_tensor)).item()\n",
    "        mae = mean_absolute_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "        mse = mean_squared_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "        \n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        print(f\"Test MSE: {mse:.4f}\")\n",
    "        \n",
    "        experimental_result.append({\"model\": str(queue[i]), \"rmse\": rmse, \"mae\": mae, \"mse\": mse})\n",
    "\n",
    "# 指定輸出檔案名稱\n",
    "csv_filename = \"model_results.csv\"\n",
    "\n",
    "# 將結果寫入 CSV 檔案\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"model\", \"rmse\", \"mae\", \"mse\"])\n",
    "    writer.writeheader()  # 寫入標題\n",
    "    writer.writerows(experimental_result)  # 寫入每行數據\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' has been created!\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(best_model.max_epochs):\n",
    "    best_model.partial_fit(X_train_tensor, y_train_tensor)\n",
    "    train_pred = best_model.predict(X_train_tensor).squeeze()\n",
    "    val_pred = best_model.predict(X_test_tensor).squeeze()\n",
    "    train_loss = mean_squared_error(y_train_tensor.numpy(), train_pred)\n",
    "    val_loss = mean_squared_error(y_test_tensor.numpy(), val_pred)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "# best_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = best_model.predict(X_test_tensor).squeeze()\n",
    "    predictions = torch.tensor(predictions)    \n",
    "    \n",
    "    # Calculate RMSE, MAE, and MSE\n",
    "    rmse = torch.sqrt(nn.MSELoss()(predictions, y_test_tensor)).item()\n",
    "    mae = mean_absolute_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "    mse = mean_squared_error(y_test_tensor.numpy(), predictions.numpy())\n",
    "    \n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test MSE: {mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
