{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew-root/miniconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/andrew-root/.cache/kagglehub/datasets/samiraalipour/genomics-of-drug-sensitivity-in-cancer-gdsc/versions/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew-root/miniconda3/envs/pytorch/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Done!\n",
      "Preprocess Done!\n",
      "數值特徵與文本特徵分配完成\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacity of 11.76 GiB of which 3.29 GiB is free. Including non-PyTorch memory, this process has 8.43 GiB memory in use. Of the allocated memory 8.26 GiB is allocated by PyTorch, and 55.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 148\u001b[0m\n\u001b[1;32m    145\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Perform forward pass\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m output_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_numeric\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型輸出維度：\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 115\u001b[0m, in \u001b[0;36mBertForNumericPrediction.forward\u001b[0;34m(self, input_ids, attention_mask, numeric_features)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, numeric_features):\n\u001b[0;32m--> 115\u001b[0m     bert_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     cls_output \u001b[38;5;241m=\u001b[39m bert_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m    117\u001b[0m     numeric_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumeric_embed(numeric_features)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1078\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1078\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    211\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(input_ids)\n\u001b[1;32m    212\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m--> 214\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken_type_embeddings\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    216\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacity of 11.76 GiB of which 3.29 GiB is free. Including non-PyTorch memory, this process has 8.43 GiB memory in use. Of the allocated memory 8.26 GiB is allocated by PyTorch, and 55.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Move data to CPU initially and only transfer to GPU when needed\n",
    "# Ensure non-model data stays on CPU as much as possible\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataLoader4BERT:\n",
    "    def __init__(self, gdsc_path, compounds_path, gdsc2_path, cell_lines_path, bert_model_name=\"bert-base-uncased\"):\n",
    "        self.gdsc_path = gdsc_path\n",
    "        self.compounds_path = compounds_path\n",
    "        self.gdsc2_path = gdsc2_path\n",
    "        self.cell_lines_path = cell_lines_path\n",
    "        self.bert_model_name = bert_model_name\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        \n",
    "        self.gdsc_dataset = None\n",
    "        self.compounds_annotation = None\n",
    "        self.gdsc2_dataset = None\n",
    "        self.cell_lines_details = None\n",
    "        self.final_df = None\n",
    "        self.X_train_text = None\n",
    "        self.X_test_text = None\n",
    "        self.X_train_numeric = None\n",
    "        self.X_test_numeric = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        \n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.define_features_and_target()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.gdsc_dataset = pd.read_csv(self.gdsc_path)\n",
    "        self.compounds_annotation = pd.read_csv(self.compounds_path)\n",
    "        self.gdsc2_dataset = pd.read_csv(self.gdsc2_path)\n",
    "        self.cell_lines_details = pd.read_excel(self.cell_lines_path)\n",
    "        print('Loading Done!')\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.gdsc_dataset = self.gdsc_dataset.dropna()\n",
    "        self.compounds_annotation = self.compounds_annotation.dropna()\n",
    "        self.gdsc2_dataset = self.gdsc2_dataset.dropna()\n",
    "        self.cell_lines_details = self.cell_lines_details.dropna()\n",
    "\n",
    "        merged_df = pd.merge(self.gdsc2_dataset, self.cell_lines_details, left_on='COSMIC_ID', right_on='COSMIC identifier', how='left')\n",
    "        self.final_df = pd.merge(merged_df, self.compounds_annotation, on='DRUG_ID', how='left')\n",
    "        print('Preprocess Done!')\n",
    "\n",
    "    def define_features_and_target(self):\n",
    "        numeric_features = ['AUC', 'Z_SCORE']\n",
    "        text_features = ['Cancer Type\\n(matching TCGA label)', \n",
    "                        'GDSC\\nTissue descriptor 1', \n",
    "                        'GDSC\\nTissue\\ndescriptor 2']\n",
    "\n",
    "        for feature in numeric_features:\n",
    "            if feature not in self.final_df.columns:\n",
    "                raise ValueError(f\"數值特徵 {feature} 不存在於 final_df 中。\")\n",
    "\n",
    "        X_numeric = self.final_df[numeric_features].fillna(0).astype(float)\n",
    "        if X_numeric.empty:\n",
    "            raise ValueError(\"數值特徵提取結果為空，請檢查數據處理步驟。\")\n",
    "\n",
    "        X_text = self.final_df[text_features].fillna('')\n",
    "        text_inputs = X_text.apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "        tokenized = self.tokenizer(text_inputs, padding=True, truncation=True, return_tensors=\"pt\", max_length=8)\n",
    "\n",
    "        if 'LN_IC50' not in self.final_df.columns:\n",
    "            raise ValueError(\"目標變數 'LN_IC50' 不存在於 final_df 中。\")\n",
    "        y = self.final_df['LN_IC50']\n",
    "\n",
    "        X_train_numeric, X_test_numeric, y_train, y_test = train_test_split(\n",
    "            X_numeric, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        input_ids_train, input_ids_test, attention_mask_train, attention_mask_test = train_test_split(\n",
    "            tokenized['input_ids'], tokenized['attention_mask'], test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        self.X_train_numeric, self.X_test_numeric = X_train_numeric, X_test_numeric\n",
    "        self.y_train, self.y_test = y_train, y_test\n",
    "        self.X_train_text = {\"input_ids\": input_ids_train, \"attention_mask\": attention_mask_train}\n",
    "        self.X_test_text = {\"input_ids\": input_ids_test, \"attention_mask\": attention_mask_test}\n",
    "\n",
    "        print(\"數值特徵與文本特徵分配完成\")\n",
    "\n",
    "    def get_data(self):\n",
    "        # Return tensors in CPU initially\n",
    "        X_train_numeric_tensor = torch.tensor(self.X_train_numeric.values).float()\n",
    "        X_test_numeric_tensor = torch.tensor(self.X_test_numeric.values).float()\n",
    "        y_train_tensor = torch.tensor(self.y_train.values).float()\n",
    "        y_test_tensor = torch.tensor(self.y_test.values).float()\n",
    "        \n",
    "        X_train_text = self.X_train_text\n",
    "        X_test_text = self.X_test_text\n",
    "\n",
    "        return X_train_numeric_tensor, X_train_text, y_train_tensor, X_test_numeric_tensor, X_test_text, y_test_tensor\n",
    "\n",
    "\n",
    "# Initialize model and only move data to GPU as needed\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertForNumericPrediction(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_numeric_features=2):\n",
    "        super(BertForNumericPrediction, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.numeric_embed = nn.Linear(num_numeric_features, self.bert.config.hidden_size)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numeric_features):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = bert_outputs.last_hidden_state[:, 0, :]\n",
    "        numeric_embedding = self.numeric_embed(numeric_features)\n",
    "        combined = torch.cat([cls_output, numeric_embedding], dim=-1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"samiraalipour/genomics-of-drug-sensitivity-in-cancer-gdsc\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataloader = DataLoader4BERT(path + '/GDSC_DATASET.csv',\n",
    "                             path + '/Compounds-annotation.csv',\n",
    "                             path + '/GDSC2-dataset.csv',\n",
    "                             path + '/Cell_Lines_Details.xlsx')\n",
    "\n",
    "X_train_numeric, X_train_text, y_train_tensor, X_test_numeric, X_test_text, y_test_tensor = dataloader.get_data()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move only necessary data to GPU\n",
    "input_ids_train = X_train_text[\"input_ids\"].to(device)\n",
    "attention_mask_train = X_train_text[\"attention_mask\"].to(device)\n",
    "X_train_numeric = X_train_numeric.to(device)\n",
    "\n",
    "model = BertForNumericPrediction(bert_model_name=\"bert-base-uncased\", num_numeric_features=X_train_numeric.shape[1])\n",
    "model = model.to(device)\n",
    "\n",
    "# Perform forward pass\n",
    "output_train = model(\n",
    "    input_ids=input_ids_train,\n",
    "    attention_mask=attention_mask_train,\n",
    "    numeric_features=X_train_numeric\n",
    ")\n",
    "\n",
    "print(\"模型輸出維度：\", output_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew-root/miniconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/andrew-root/.cache/kagglehub/datasets/samiraalipour/genomics-of-drug-sensitivity-in-cancer-gdsc/versions/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew-root/miniconda3/envs/pytorch/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Done!\n",
      "Preprocess Done!\n",
      "數值特徵與文本特徵分配完成\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "BERT 模型在 forward 過程中發生錯誤: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacity of 11.76 GiB of which 11.10 GiB is free. Including non-PyTorch memory, this process has 638.00 MiB memory in use. Of the allocated memory 484.74 MiB is allocated by PyTorch, and 51.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 141\u001b[0m, in \u001b[0;36mBertForNumericPrediction.forward\u001b[0;34m(self, input_ids, attention_mask, numeric_features)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# 通過 BERT 獲取文本特徵\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     bert_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     cls_output \u001b[38;5;241m=\u001b[39m bert_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# 提取 [CLS] 標記的輸出\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1078\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1078\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacity of 11.76 GiB of which 11.10 GiB is free. Including non-PyTorch memory, this process has 638.00 MiB memory in use. Of the allocated memory 484.74 MiB is allocated by PyTorch, and 51.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 189\u001b[0m\n\u001b[1;32m    186\u001b[0m X_train_numeric \u001b[38;5;241m=\u001b[39m X_train_numeric\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# 將數據傳入模型\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m output_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_numeric\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# 打印輸出維度\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型輸出維度：\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 144\u001b[0m, in \u001b[0;36mBertForNumericPrediction.forward\u001b[0;34m(self, input_ids, attention_mask, numeric_features)\u001b[0m\n\u001b[1;32m    142\u001b[0m     cls_output \u001b[38;5;241m=\u001b[39m bert_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# 提取 [CLS] 標記的輸出\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERT 模型在 forward 過程中發生錯誤: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# 數值特徵嵌入\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     numeric_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumeric_embed(numeric_features)  \u001b[38;5;66;03m# 將數值特徵嵌入到與文本特徵相同的維度\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: BERT 模型在 forward 過程中發生錯誤: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacity of 11.76 GiB of which 11.10 GiB is free. Including non-PyTorch memory, this process has 638.00 MiB memory in use. Of the allocated memory 484.74 MiB is allocated by PyTorch, and 51.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader4BERT:\n",
    "    def __init__(self, gdsc_path, compounds_path, gdsc2_path, cell_lines_path, bert_model_name=\"bert-base-uncased\"):\n",
    "        self.gdsc_path = gdsc_path\n",
    "        self.compounds_path = compounds_path\n",
    "        self.gdsc2_path = gdsc2_path\n",
    "        self.cell_lines_path = cell_lines_path\n",
    "        self.bert_model_name = bert_model_name\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        \n",
    "        self.gdsc_dataset = None\n",
    "        self.compounds_annotation = None\n",
    "        self.gdsc2_dataset = None\n",
    "        self.cell_lines_details = None\n",
    "        self.final_df = None\n",
    "        self.X_train_text = None\n",
    "        self.X_test_text = None\n",
    "        self.X_train_numeric = None\n",
    "        self.X_test_numeric = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        \n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.define_features_and_target()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.gdsc_dataset = pd.read_csv(self.gdsc_path)\n",
    "        self.compounds_annotation = pd.read_csv(self.compounds_path)\n",
    "        self.gdsc2_dataset = pd.read_csv(self.gdsc2_path)\n",
    "        self.cell_lines_details = pd.read_excel(self.cell_lines_path)\n",
    "        print('Loading Done!')\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.gdsc_dataset = self.gdsc_dataset.dropna()\n",
    "        self.compounds_annotation = self.compounds_annotation.dropna()\n",
    "        self.gdsc2_dataset = self.gdsc2_dataset.dropna()\n",
    "        self.cell_lines_details = self.cell_lines_details.dropna()\n",
    "\n",
    "        merged_df = pd.merge(self.gdsc2_dataset, self.cell_lines_details, left_on='COSMIC_ID', right_on='COSMIC identifier', how='left')\n",
    "        self.final_df = pd.merge(merged_df, self.compounds_annotation, on='DRUG_ID', how='left')\n",
    "        print('Preprocess Done!')\n",
    "\n",
    "    def define_features_and_target(self):\n",
    "        # 數值特徵\n",
    "        numeric_features = ['AUC', 'Z_SCORE']\n",
    "        # 文本特徵\n",
    "        text_features = ['Cancer Type\\n(matching TCGA label)', \n",
    "                        'GDSC\\nTissue descriptor 1', \n",
    "                        'GDSC\\nTissue\\ndescriptor 2']\n",
    "        \n",
    "        # 檢查數值特徵是否存在於 DataFrame\n",
    "        for feature in numeric_features:\n",
    "            if feature not in self.final_df.columns:\n",
    "                raise ValueError(f\"數值特徵 {feature} 不存在於 final_df 中。\")\n",
    "\n",
    "        # 提取數值和文本特徵\n",
    "        X_numeric = self.final_df[numeric_features].fillna(0).astype(float)\n",
    "        if X_numeric.empty:\n",
    "            raise ValueError(\"數值特徵提取結果為空，請檢查數據處理步驟。\")\n",
    "\n",
    "        # 文本特徵處理\n",
    "        X_text = self.final_df[text_features].fillna('')\n",
    "        text_inputs = X_text.apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "        tokenized = self.tokenizer(text_inputs, padding=True, truncation=True, return_tensors=\"pt\", max_length=64)\n",
    "\n",
    "        # 目標變數\n",
    "        if 'LN_IC50' not in self.final_df.columns:\n",
    "            raise ValueError(\"目標變數 'LN_IC50' 不存在於 final_df 中。\")\n",
    "        y = self.final_df['LN_IC50']\n",
    "\n",
    "        # 拆分數據集\n",
    "        X_train_numeric, X_test_numeric, y_train, y_test = train_test_split(\n",
    "            X_numeric, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        input_ids_train, input_ids_test, attention_mask_train, attention_mask_test = train_test_split(\n",
    "            tokenized['input_ids'], tokenized['attention_mask'], test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # 分配數據\n",
    "        self.X_train_numeric, self.X_test_numeric = X_train_numeric, X_test_numeric\n",
    "        self.y_train, self.y_test = y_train, y_test\n",
    "        self.X_train_text = {\"input_ids\": input_ids_train, \"attention_mask\": attention_mask_train}\n",
    "        self.X_test_text = {\"input_ids\": input_ids_test, \"attention_mask\": attention_mask_test}\n",
    "\n",
    "        print(\"數值特徵與文本特徵分配完成\")\n",
    "\n",
    "    def get_data(self):\n",
    "        # 數值特徵轉換為 tensor\n",
    "        X_train_numeric_tensor = torch.tensor(self.X_train_numeric.values).float()\n",
    "        X_test_numeric_tensor = torch.tensor(self.X_test_numeric.values).float()\n",
    "        y_train_tensor = torch.tensor(self.y_train.values).float()\n",
    "        y_test_tensor = torch.tensor(self.y_test.values).float()\n",
    "        \n",
    "        # 文本特徵保持 tokenized 格式\n",
    "        X_train_text = self.X_train_text\n",
    "        X_test_text = self.X_test_text\n",
    "\n",
    "        return X_train_numeric_tensor, X_train_text, y_train_tensor, X_test_numeric_tensor, X_test_text, y_test_tensor\n",
    "\n",
    "\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertForNumericPrediction(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_numeric_features=2):\n",
    "        super(BertForNumericPrediction, self).__init__()\n",
    "        # 初始化 BERT 模型\n",
    "        try:\n",
    "            self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"無法加載 BERT 模型 {bert_model_name}，錯誤訊息: {e}\")\n",
    "        \n",
    "        # 數值特徵嵌入層\n",
    "        self.numeric_embed = nn.Linear(num_numeric_features, self.bert.config.hidden_size)\n",
    "        # 數值與文本特徵融合後的輸出層\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size * 2, 1)  # 融合後的輸出層\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numeric_features):\n",
    "        # 檢查輸入尺寸是否正確\n",
    "        if input_ids.size(0) != numeric_features.size(0):\n",
    "            raise ValueError(\n",
    "                f\"input_ids 和 numeric_features 的 batch size 不匹配：\"\n",
    "                f\"{input_ids.size(0)} != {numeric_features.size(0)}\"\n",
    "            )\n",
    "        if numeric_features.size(1) != self.numeric_embed.in_features:\n",
    "            raise ValueError(\n",
    "                f\"numeric_features 的特徵數量錯誤：\"\n",
    "                f\"{numeric_features.size(1)} != {self.numeric_embed.in_features}\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            # 通過 BERT 獲取文本特徵\n",
    "            bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_output = bert_outputs.last_hidden_state[:, 0, :]  # 提取 [CLS] 標記的輸出\n",
    "        except RuntimeError as e:\n",
    "            raise RuntimeError(f\"BERT 模型在 forward 過程中發生錯誤: {e}\")\n",
    "\n",
    "        try:\n",
    "            # 數值特徵嵌入\n",
    "            numeric_embedding = self.numeric_embed(numeric_features)  # 將數值特徵嵌入到與文本特徵相同的維度\n",
    "        except RuntimeError as e:\n",
    "            raise RuntimeError(f\"數值特徵嵌入層發生錯誤: {e}\")\n",
    "\n",
    "        try:\n",
    "            # 特徵融合\n",
    "            combined = torch.cat([cls_output, numeric_embedding], dim=-1)\n",
    "            \n",
    "            # 最終預測\n",
    "            output = self.fc(combined)\n",
    "        except RuntimeError as e:\n",
    "            raise RuntimeError(f\"特徵融合或輸出層計算時發生錯誤: {e}\")\n",
    "\n",
    "        return output\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"samiraalipour/genomics-of-drug-sensitivity-in-cancer-gdsc\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataloader = DataLoader4BERT(path + '/GDSC_DATASET.csv',\n",
    "                             path + '/Compounds-annotation.csv',\n",
    "                             path + '/GDSC2-dataset.csv',\n",
    "                             path + '/Cell_Lines_Details.xlsx')\n",
    "\n",
    "# 獲取數據\n",
    "X_train_numeric, X_train_text, y_train_tensor, X_test_numeric, X_test_text, y_test_tensor = dataloader.get_data()\n",
    "\n",
    "# 初始化模型\n",
    "model = BertForNumericPrediction(bert_model_name=\"bert-base-uncased\", num_numeric_features=X_train_numeric.shape[1])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 將數據移至設備\n",
    "input_ids_train = X_train_text[\"input_ids\"].to(device)\n",
    "attention_mask_train = X_train_text[\"attention_mask\"].to(device)\n",
    "X_train_numeric = X_train_numeric.to(device)\n",
    "\n",
    "# 將數據傳入模型\n",
    "output_train = model(\n",
    "    input_ids=input_ids_train,\n",
    "    attention_mask=attention_mask_train,\n",
    "    numeric_features=X_train_numeric\n",
    ")\n",
    "\n",
    "# 打印輸出維度\n",
    "print(\"模型輸出維度：\", output_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
